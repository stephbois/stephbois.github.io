{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khEhhmEdDQtA"
      },
      "source": [
        "**Tutorial 2**\n",
        "\n",
        "This tutorial is based on using  ML package Weka for machine learning. Weka is a famous machine learning software and a set of libraries that one can use within a programming language. Weka was created at the University of Waikato, New Zealnd (https://www.cs.waikato.ac.nz/ml/weka/). It is accompanied with a text book of data mining taught in schools around the world (https://www.cs.waikato.ac.nz/ml/weka/book.html). The advantage of using Weka's Python package is that the implementation of algorithms is complete, comprehsive and easy to use. Let's see below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNlbkyZYFvoX"
      },
      "source": [
        "First install Weka's Python package."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koJw1ZNd5n6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27ee4b1f-385f-4009-d84e-70a1862a625c"
      },
      "source": [
        "! pip install python-weka-wrapper3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-weka-wrapper3\n",
            "  Using cached python-weka-wrapper3-0.2.14.tar.gz (15.9 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-javabridge>=4.0.0 (from python-weka-wrapper3)\n",
            "  Using cached python-javabridge-4.0.3.tar.gz (1.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-weka-wrapper3) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from python-weka-wrapper3) (23.2)\n",
            "Collecting configurable-objects (from python-weka-wrapper3)\n",
            "  Downloading configurable-objects-0.0.1.tar.gz (4.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting simple-data-flow (from python-weka-wrapper3)\n",
            "  Downloading simple-data-flow-0.0.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: python-weka-wrapper3, python-javabridge, configurable-objects, simple-data-flow\n",
            "  Building wheel for python-weka-wrapper3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-weka-wrapper3: filename=python_weka_wrapper3-0.2.14-py3-none-any.whl size=14496261 sha256=ab3837d82113283cfa10c9081cad954081e365bca5841bdcbb1289f783f88d6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/c5/f2/412fa8d3b181151e11b68d46daa52f96e9b832a2eca4bc6c88\n",
            "  Building wheel for python-javabridge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-javabridge: filename=python_javabridge-4.0.3-cp310-cp310-linux_x86_64.whl size=1743202 sha256=9800b1814f6ce4ecca6fde97fc68347e0f4e382265f359d71171577869ba1f5e\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/58/be/c5d71b71a9dd6585f897fa5b2d021e03962eb30d6b20797396\n",
            "  Building wheel for configurable-objects (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configurable-objects: filename=configurable_objects-0.0.1-py3-none-any.whl size=4695 sha256=065119d3475e4b1b31a28024abcd16c272ce33d62aa7b582762e1bc92d50809e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/11/bc/75ac8b0592c38dc42412942c37d3947faf0b222bad150132a1\n",
            "  Building wheel for simple-data-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simple-data-flow: filename=simple_data_flow-0.0.1-py3-none-any.whl size=19060 sha256=4050fc28292f02b7154b598dab3cecfe0c251fb660718bcd08d5db22cf774e41\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/02/23/4aec0db3dae7152dd268d6de385905116af55229c1a8e81303\n",
            "Successfully built python-weka-wrapper3 python-javabridge configurable-objects simple-data-flow\n",
            "Installing collected packages: configurable-objects, simple-data-flow, python-javabridge, python-weka-wrapper3\n",
            "Successfully installed configurable-objects-0.0.1 python-javabridge-4.0.3 python-weka-wrapper3-0.2.14 simple-data-flow-0.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpl1jBlgDXXG"
      },
      "source": [
        "Weka was built on Java, and below we shall be setting Java and launching it in Python environment. Don't worry about understanding this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7q53sHc7JXM"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path\n",
        "sys.path.append(\"/usr/lib/jvm/java-11-openjdk-amd64/bin/\")\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64/\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqBmTg0T7UoD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29105d8-7014-4ef1-efb3-441e494951bc"
      },
      "source": [
        "\n",
        "import weka.core.jvm as jvm\n",
        "jvm.start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:weka.core.jvm:Adding bundled jars\n",
            "DEBUG:weka.core.jvm:Classpath=['/usr/local/lib/python3.10/dist-packages/javabridge/jars/rhino-1.7R4.jar', '/usr/local/lib/python3.10/dist-packages/javabridge/jars/runnablequeue.jar', '/usr/local/lib/python3.10/dist-packages/javabridge/jars/cpython.jar', '/usr/local/lib/python3.10/dist-packages/weka/lib/core.jar', '/usr/local/lib/python3.10/dist-packages/weka/lib/weka.jar', '/usr/local/lib/python3.10/dist-packages/weka/lib/arpack_combined.jar', '/usr/local/lib/python3.10/dist-packages/weka/lib/mtj.jar', '/usr/local/lib/python3.10/dist-packages/weka/lib/python-weka-wrapper.jar']\n",
            "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
            "DEBUG:weka.core.jvm:Package support disabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDyzyakqGxbK"
      },
      "source": [
        "We shall now upload a dataset file. Weka works with arff format easily, it can load CSV too. We shall upload .arff file because I have defined the correct data types of variables (cagtegorical or numerical) in it already."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "950wamGU8feo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "b9cbda5a-ee6b-4d04-af10-c7b9bb6d9e26"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a2017951-8162-4704-baa1-e30d8c0a52a0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a2017951-8162-4704-baa1-e30d8c0a52a0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving bank.arff to bank.arff\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFib_6h4LFN-"
      },
      "source": [
        "Let's load our dataset into memory. It will be loaded using the following code. Dataset file that I have uplaoded is german_credit.arff. Note this loaded data in moemeory is not a Pandas' data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J71IoLXo7ehS"
      },
      "source": [
        "from weka.core.converters import Loader\n",
        "from weka.core.classes import Random\n",
        "from weka.classifiers import Classifier, Evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loHpb71i8Qc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f10380-c7fa-4843-e510-4c807fce32a0"
      },
      "source": [
        "loader = Loader(classname=\"weka.core.converters.ArffLoader\")\n",
        "#data_file = 'german_credit.arff'\n",
        "#data_file=\"churn.arff\"\n",
        "data_file=\"bank.arff\"\n",
        "data = filtered_data\n",
        "\n",
        "print('Data set size: ', data.num_instances)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data set size:  4521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7nY5H1H9IKg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56714fc-112b-43ca-e4fc-88f84ecd3931"
      },
      "source": [
        "#Let's look at the attributes and their types\n",
        "# We have two data types here: categorical and numeric.\n",
        "for i in range(data.num_attributes):\n",
        "  print (\"index \",i)\n",
        "  print(data.attribute(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index  0\n",
            "@attribute age numeric\n",
            "index  1\n",
            "@attribute duration numeric\n",
            "index  2\n",
            "@attribute poutcome {unknown,failure,other,success}\n",
            "index  3\n",
            "@attribute y {no,yes}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxf6oxNvNhQ3"
      },
      "source": [
        "Index of class attribute in our data is 0--creditability. It can be observed above. I am setting up class attribute here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ-tqCQhJzNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afa1705-7844-439b-dad5-568727ef91d3"
      },
      "source": [
        "\n",
        "# index of class atrribute is 0 (Creditability) for German credit card\n",
        "# index of class attribute is 20(Churn) for Churn data set\n",
        "# index of class attribute is 16(y) for bank data set\n",
        "# Again, you can see all the index numbers for attributes by running the previous cell\n",
        "class_idx=3\n",
        "print('Will be classifying on: ', data.attribute(class_idx))\n",
        "data.class_index = class_idx\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will be classifying on:  @attribute y {no,yes}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhXhHmnPOAUz"
      },
      "source": [
        "Time to split dataset into train and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G28k9AC_N_Fa"
      },
      "source": [
        "# Splitting 66% for training and 34% for testing using a seed of 1 for random number generator\n",
        "train, test = data.train_test_split(66.0, Random(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mzdxH9FOM13"
      },
      "source": [
        "We are now going to train a decision tree. This decision tree is C4.5 decision tree and it's name in Weka is J48. Good thing about this decision tree is that it is the exact implementation of the C4.5 decision tree as in theory and as we studied. C4.5 decision tree algorithm can handle numeric and categorical attributes by itself. So there is no need to convert categorical features(or variables) to numeric features by using on-hot-encoding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gktcxueb9Bc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79452da1-13ff-4dac-ed43-37eaac1dadc8"
      },
      "source": [
        "# We are generating a pruned C4.5 decision tree, with a confidence factor used for pruning of 0.25.\n",
        "# You can change it to different threshold values to change the size of the tree.\n",
        "cls = Classifier(classname=\"weka.classifiers.trees.J48\", options=[\"-C\", \"0.25\"])\n",
        "cls.build_classifier(train)\n",
        "# See the tree below.\n",
        "print(cls)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J48 pruned tree\n",
            "------------------\n",
            "\n",
            "duration <= 221: no (1780.0/54.0)\n",
            "duration > 221\n",
            "|   duration <= 645\n",
            "|   |   poutcome = unknown\n",
            "|   |   |   age <= 59: no (746.0/79.0)\n",
            "|   |   |   age > 59\n",
            "|   |   |   |   age <= 70\n",
            "|   |   |   |   |   age <= 60: no (10.0/1.0)\n",
            "|   |   |   |   |   age > 60\n",
            "|   |   |   |   |   |   age <= 68: yes (13.0/5.0)\n",
            "|   |   |   |   |   |   age > 68: no (3.0)\n",
            "|   |   |   |   age > 70: yes (5.0)\n",
            "|   |   poutcome = failure: no (99.0/21.0)\n",
            "|   |   poutcome = other: no (41.0/15.0)\n",
            "|   |   poutcome = success: yes (47.0/12.0)\n",
            "|   duration > 645: yes (240.0/117.0)\n",
            "\n",
            "Number of Leaves  : \t10\n",
            "\n",
            "Size of the tree : \t17\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpiUmoFnQ-Zn"
      },
      "source": [
        "In the above tree, these values \": 1 (8.0/2.0)\" means the class at the leaf is 1, total training records during evlaution on the training set after building the tree reached here are 8 but only 2 of them were incorrectly predicted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTdZr1WrC60O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3505a94-9c82-41ca-b534-e83b4bac2e76"
      },
      "source": [
        "import weka.plot.graph as graph  # If pygrpahviz is installed, you can plot the graph of tree too but it may not work\n",
        "graph.plot_dot_graph(cls.graph)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:weka.plot.graph:Pygraphviz is not installed, cannot generate graph plot!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHWvxNY1-exr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b18020-f9ab-45d9-edf1-5345caed932a"
      },
      "source": [
        "# Let's evaluate it on the test set\n",
        "\n",
        "evl = Evaluation(train)\n",
        "evl.test_model(cls, test)\n",
        "print(evl.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correctly Classified Instances        1366               88.8744 %\n",
            "Incorrectly Classified Instances       171               11.1256 %\n",
            "Kappa statistic                          0.4275\n",
            "Mean absolute error                      0.1582\n",
            "Root mean squared error                  0.2866\n",
            "Relative absolute error                 77.2531 %\n",
            "Root relative squared error             89.1181 %\n",
            "Total Number of Instances             1537     \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKTPcA9x-tuZ"
      },
      "source": [
        "Here \"Correctly Classified Instances\"   means accuracy, and \"Total Number of Instances\" means total records in the test set. Ignore everything else as we have not studied them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yJrmk2o--So",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b693d837-01f8-4397-9d6d-2ef1df3af0e5"
      },
      "source": [
        "# Here are all the metrics\n",
        "#print (\"Class Index \", class_idx)\n",
        "print(\"Classes at different positions are \",data.attribute(class_idx))\n",
        "\n",
        "print(\"confusion Matrix\")\n",
        "#Note that the TP here will be for the class at the first position printed by the previous line and TN will be for the class at second position\n",
        "print(evl.confusion_matrix)\n",
        "\n",
        "###############\n",
        "# Print metrics for the first class\n",
        "##############\n",
        "class_position=0\n",
        "print(\"\")\n",
        "print (\"Evaluation from the perspective of class at position \"+ str(class_position))\n",
        "print(\"TP \",evl.true_positive_rate(class_position))\n",
        "print(\"FP\",evl.false_positive_rate(class_position))\n",
        "print(\"Precision \",evl.precision(class_position))\n",
        "print(\"Recall \",evl.recall(class_position))\n",
        "\n",
        "\n",
        "###############\n",
        "# Print metrics for the second class\n",
        "##############\n",
        "class_position=1\n",
        "print(\"\")\n",
        "print (\"Evaluation from the perspective of class at position \"+ str(class_position))\n",
        "print(\"TP \",evl.true_positive_rate(class_position))\n",
        "print(\"FP\",evl.false_positive_rate(class_position))\n",
        "print(\"Precision \",evl.precision(class_position))\n",
        "print(\"Recall \",evl.recall(class_position))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes at different positions are  @attribute y {no,yes}\n",
            "confusion Matrix\n",
            "[[1284.   73.]\n",
            " [  98.   82.]]\n",
            "\n",
            "Evaluation from the perspective of class at position 0\n",
            "TP  0.94620486366986\n",
            "FP 0.5444444444444444\n",
            "Precision  0.9290882778581766\n",
            "Recall  0.94620486366986\n",
            "\n",
            "Evaluation from the perspective of class at position 1\n",
            "TP  0.45555555555555555\n",
            "FP 0.05379513633014001\n",
            "Precision  0.5290322580645161\n",
            "Recall  0.45555555555555555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbmNrC80CQef"
      },
      "source": [
        "**Naive Bayes**\n",
        "\n",
        "Below is the code to run Naive Bayes algorithm. It is a different version of Naive Bayes that is suited to both numeric and categorical features(atrributes or variables).\n",
        " (https://weka.sourceforge.io/doc.dev/weka/classifiers/bayes/NaiveBayes.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6sCeXdxCUA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c09dd238-cf33-4a43-e26d-46c902978c6a"
      },
      "source": [
        "\n",
        "nb = Classifier(classname=\"weka.classifiers.bayes.NaiveBayes\")\n",
        "nb.build_classifier(train)\n",
        "#let's understand the NB model by printing it\n",
        "print(nb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Classifier\n",
            "\n",
            "                  Class\n",
            "Attribute            no      yes\n",
            "                 (0.89)   (0.11)\n",
            "=================================\n",
            "age\n",
            "  mean           41.0167  42.6333\n",
            "  std. dev.      10.1781  13.1354\n",
            "  weight sum        2643      341\n",
            "  precision       1.0794   1.0794\n",
            "\n",
            "duration\n",
            "  mean          224.3443 559.0086\n",
            "  std. dev.     204.4182 400.6621\n",
            "  weight sum        2643      341\n",
            "  precision       3.6239   3.6239\n",
            "\n",
            "poutcome\n",
            "  unknown         2221.0    224.0\n",
            "  failure          292.0     39.0\n",
            "  other            101.0     27.0\n",
            "  success           33.0     55.0\n",
            "  [total]         2647.0    345.0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXe-81rZKL4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292af1a7-97ff-4b77-8d04-216c1ad36f1b"
      },
      "source": [
        "# Time for evaluation on the test set\n",
        "evl_nb = Evaluation(train)\n",
        "evl_nb.test_model(nb, test)\n",
        "print(evl_nb.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correctly Classified Instances        1367               88.9395 %\n",
            "Incorrectly Classified Instances       170               11.0605 %\n",
            "Kappa statistic                          0.3452\n",
            "Mean absolute error                      0.1424\n",
            "Root mean squared error                  0.2929\n",
            "Relative absolute error                 69.5067 %\n",
            "Root relative squared error             91.0816 %\n",
            "Total Number of Instances             1537     \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFZOrkc-KTon",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b294c4ae-51b0-44b7-8e03-38451ccd38c4"
      },
      "source": [
        "#Here are all the metrics for Naive Bayes\n",
        "\n",
        "print(\"Classes at different positions are \",data.attribute(class_idx))\n",
        "\n",
        "print(\"confusion Matrix\")\n",
        "#Note that the TP here will be for the class at the first position printed by the previous line\n",
        "print(evl_nb.confusion_matrix)\n",
        "\n",
        "###############\n",
        "# Print metrics for the first class\n",
        "##############\n",
        "class_position=0\n",
        "print(\"\")\n",
        "print (\"Evaluation from the perspective of class at position \"+ str(class_position))\n",
        "print(\"TP \",evl_nb.true_positive_rate(class_position))\n",
        "print(\"FP\",evl_nb.false_positive_rate(class_position))\n",
        "print(\"Precision \",evl_nb.precision(class_position))\n",
        "print(\"Recall \",evl_nb.recall(class_position))\n",
        "\n",
        "\n",
        "###############\n",
        "# Print metrics for the second class\n",
        "##############\n",
        "class_position=1\n",
        "print(\"\")\n",
        "print (\"Evaluation from the perspective of class at position \"+ str(class_position))\n",
        "print(\"TP \",evl_nb.true_positive_rate(class_position))\n",
        "print(\"FP\",evl_nb.false_positive_rate(class_position))\n",
        "print(\"Precision \",evl_nb.precision(class_position))\n",
        "print(\"Recall \",evl_nb.recall(class_position))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes at different positions are  @attribute y {no,yes}\n",
            "confusion Matrix\n",
            "[[1310.   47.]\n",
            " [ 123.   57.]]\n",
            "\n",
            "Evaluation from the perspective of class at position 0\n",
            "TP  0.9653647752394989\n",
            "FP 0.6833333333333333\n",
            "Precision  0.9141660851360781\n",
            "Recall  0.9653647752394989\n",
            "\n",
            "Evaluation from the perspective of class at position 1\n",
            "TP  0.31666666666666665\n",
            "FP 0.034635224760501106\n",
            "Precision  0.5480769230769231\n",
            "Recall  0.31666666666666665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly_pw4iyEDeU"
      },
      "source": [
        "**Appendix**\n",
        "\n",
        "Using the following code  you can find out the best attribute by using the BestFIRst algorithm in Weka. Again it is not necessary to understand the whole code below but if you wanna learn more about BesrFirst and CfsSubsetEval, you can go here https://weka.sourceforge.io/doc.dev/weka/attributeSelection/package-summary.html. You can also replace them with options available on the above site.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWeZT913ENxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9d4cd0-cb24-421a-e4da-92de5903931b"
      },
      "source": [
        "from weka.attribute_selection import ASSearch, ASEvaluation, AttributeSelection\n",
        "search = ASSearch(classname=\"weka.attributeSelection.BestFirst\", options=[\"-D\", \"1\", \"-N\", \"5\"])\n",
        "evaluator = ASEvaluation(classname=\"weka.attributeSelection.CfsSubsetEval\", options=[\"-P\", \"1\", \"-E\", \"1\"])\n",
        "attsel = AttributeSelection()\n",
        "attsel.search(search)\n",
        "attsel.evaluator(evaluator)\n",
        "attsel.select_attributes(data)\n",
        "\n",
        "print(\"# attributes: \" + str(attsel.number_attributes_selected))\n",
        "print(\"attributes: \" + str(attsel.selected_attributes))\n",
        "print(\"result string:\\n\" + attsel.results_string)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# attributes: 3\n",
            "attributes: [ 0 11 15 16]\n",
            "result string:\n",
            "\n",
            "\n",
            "=== Attribute Selection on all input data ===\n",
            "\n",
            "Search Method:\n",
            "\tBest first.\n",
            "\tStart set: no attributes\n",
            "\tSearch direction: forward\n",
            "\tStale search after 5 node expansions\n",
            "\tTotal number of subsets evaluated: 97\n",
            "\tMerit of best subset found:    0.095\n",
            "\n",
            "Attribute Subset Evaluator (supervised, Class (nominal): 17 y):\n",
            "\tCFS Subset Evaluator\n",
            "\tIncluding locally predictive attributes\n",
            "\n",
            "Selected attributes: 1,12,16 : 3\n",
            "                     age\n",
            "                     duration\n",
            "                     poutcome\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3wsg8UrEVNu"
      },
      "source": [
        "Weka's best first search method resulted into above attributes selection. Let's create a new copy of dataset with those attributes only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiPY3RyLElE6"
      },
      "source": [
        "# As you see above, we only attributes 2,3 and 4 are important as judged by Weka for German Credit card data set. So we are going to load\n",
        "# data again and remove all the attributes from 5-21. Atrribute at index 1 is the class atrribute, so we'll keep that too\n",
        "from weka.filters import Filter\n",
        "\n",
        "data2 = loader.load_file(data_file)\n",
        "# Filtering method 1\n",
        "#remove = Filter(classname=\"weka.filters.unsupervised.attribute.Remove\", options=[\"-R\", \"5-21\"])\n",
        "#remove.inputformat(data2)\n",
        "#filtered_data = remove.filter(data2)\n",
        "\n",
        "#print(filtered_data.subset(row_range=\"1-10\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LqlELU2HlcF"
      },
      "source": [
        "#Filtering method 2\n",
        "#Another way of filtering columns usingthe following code. Here we are keeping only features 1-4 and 7.\n",
        "filtered_data=data2.subset(col_range='1, 12, 16, 17')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk0qKKu8DY6q"
      },
      "source": [
        "Now you can remove the above filtered data set as an input data set in the code examples shown above and repeat the experiments.\n",
        "\n",
        "More examples on the use of different functionalities of Weka's Python package are here for curious readers:\n",
        "http://fracpete.github.io/python-weka-wrapper3/examples.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycH40LlVHJ3L"
      },
      "source": [
        "#If you are done stop the JVM (Java Virtual Machine)\n",
        "jvm.stop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivD_4uBbW9wP"
      },
      "source": [
        "It turns out that Weka's python package is easier and comprehensive than other Python packages.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "For CIND 119 course at Ryerson\n",
        "  by Syed Shariyar Murtaza,Ph.D.\n",
        "```\n",
        "\n"
      ]
    }
  ]
}